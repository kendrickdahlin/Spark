Spark Executor Command: "/Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java" "-cp" "/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/conf/:/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/jars/*" "-Xmx1024M" "-Dspark.driver.port=50543" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:50543" "--executor-id" "211" "--hostname" "192.168.1.105" "--cores" "8" "--app-id" "app-20240516121010-0032" "--worker-url" "spark://Worker@192.168.1.105:49187" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/05/16 12:21:33 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 6888@dyn230-001.wireless-1725.ndsu.NoDak.edu
24/05/16 12:21:33 INFO SignalUtils: Registering signal handler for TERM
24/05/16 12:21:33 INFO SignalUtils: Registering signal handler for HUP
24/05/16 12:21:33 INFO SignalUtils: Registering signal handler for INT
24/05/16 12:21:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/05/16 12:21:33 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/16 12:21:33 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/16 12:21:33 INFO SecurityManager: Changing view acls groups to: 
24/05/16 12:21:33 INFO SecurityManager: Changing modify acls groups to: 
24/05/16 12:21:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/16 12:21:34 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.NoDak.edu/172.25.230.1:50543 after 67 ms (0 ms spent in bootstraps)
24/05/16 12:21:34 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/16 12:21:34 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/16 12:21:34 INFO SecurityManager: Changing view acls groups to: 
24/05/16 12:21:34 INFO SecurityManager: Changing modify acls groups to: 
24/05/16 12:21:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/16 12:21:34 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.NoDak.edu/172.25.230.1:50543 after 2 ms (0 ms spent in bootstraps)
24/05/16 12:21:34 INFO DiskBlockManager: Created local directory at /private/var/folders/rh/d6ltsplj4f94dtzy8y9sz6lr0000gn/T/spark-676a89f7-fd34-4663-bc85-eef08191020a/executor-d6928acc-e489-4f80-81ab-c54b0a36b54d/blockmgr-f7cbd694-3811-4de2-89e9-ba88f737bde3
24/05/16 12:21:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/05/16 12:21:34 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:50543
24/05/16 12:21:34 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.105:49187
24/05/16 12:21:34 INFO ResourceUtils: ==============================================================
24/05/16 12:21:34 INFO ResourceUtils: No custom resources configured for spark.executor.
24/05/16 12:21:34 INFO ResourceUtils: ==============================================================
24/05/16 12:21:34 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/05/16 12:21:34 INFO Executor: Starting executor ID 211 on host 192.168.1.105
24/05/16 12:21:34 INFO Executor: OS info Mac OS X, 14.4.1, x86_64
24/05/16 12:21:34 INFO Executor: Java version 1.8.0_401
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/16 12:21:34 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Can't assign requested address: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
java.net.BindException: Can't assign requested address: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:438)
	at sun.nio.ch.Net.bind(Net.java:430)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:225)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:141)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:600)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:579)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
24/05/16 12:21:34 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/05/16 12:21:34 INFO MemoryStore: MemoryStore cleared
24/05/16 12:21:34 INFO BlockManager: BlockManager stopped
24/05/16 12:21:34 INFO ShutdownHookManager: Shutdown hook called
