Spark Executor Command: "/Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java" "-cp" "/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/conf/:/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/jars/*" "-Xmx1024M" "-Dspark.driver.port=63281" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:63281" "--executor-id" "312" "--hostname" "172.25.230.1" "--cores" "8" "--app-id" "app-20240511204204-0020" "--worker-url" "spark://Worker@172.25.230.1:50901" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/05/14 09:30:42 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 97319@Aarons-MacBook-Pro-2.local
24/05/14 09:30:42 INFO SignalUtils: Registering signal handler for TERM
24/05/14 09:30:42 INFO SignalUtils: Registering signal handler for HUP
24/05/14 09:30:42 INFO SignalUtils: Registering signal handler for INT
24/05/14 09:30:42 WARN Utils: Your hostname, Aarons-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.25.230.1 instead (on interface en0)
24/05/14 09:30:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
24/05/14 09:30:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/05/14 09:30:44 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/14 09:30:44 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/14 09:30:44 INFO SecurityManager: Changing view acls groups to: 
24/05/14 09:30:44 INFO SecurityManager: Changing modify acls groups to: 
24/05/14 09:30:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/14 09:30:44 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.nodak.edu/172.25.230.1:63281 after 68 ms (0 ms spent in bootstraps)
24/05/14 09:30:44 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/14 09:30:44 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/14 09:30:44 INFO SecurityManager: Changing view acls groups to: 
24/05/14 09:30:44 INFO SecurityManager: Changing modify acls groups to: 
24/05/14 09:30:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/14 09:30:44 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.nodak.edu/172.25.230.1:63281 after 2 ms (0 ms spent in bootstraps)
24/05/14 09:30:44 INFO DiskBlockManager: Created local directory at /private/var/folders/rh/d6ltsplj4f94dtzy8y9sz6lr0000gn/T/spark-a650efa9-c97f-462c-aa15-8b9d5ca02f7f/executor-6a868077-836d-4f08-85f0-8e89105020a9/blockmgr-8fe5659c-ef7e-441e-bcab-1c4134574084
24/05/14 09:30:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:63281
24/05/14 09:30:45 INFO WorkerWatcher: Connecting to worker spark://Worker@172.25.230.1:50901
24/05/14 09:30:45 INFO TransportClientFactory: Successfully created connection to /172.25.230.1:50901 after 5 ms (0 ms spent in bootstraps)
24/05/14 09:30:45 INFO WorkerWatcher: Successfully connected to spark://Worker@172.25.230.1:50901
24/05/14 09:30:45 INFO ResourceUtils: ==============================================================
24/05/14 09:30:45 INFO ResourceUtils: No custom resources configured for spark.executor.
24/05/14 09:30:45 INFO ResourceUtils: ==============================================================
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/05/14 09:30:45 INFO Executor: Starting executor ID 312 on host 172.25.230.1
24/05/14 09:30:45 INFO Executor: OS info Mac OS X, 14.4.1, x86_64
24/05/14 09:30:45 INFO Executor: Java version 1.8.0_401
24/05/14 09:30:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51743.
24/05/14 09:30:45 INFO NettyBlockTransferService: Server created on 172.25.230.1:51743
24/05/14 09:30:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/05/14 09:30:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(312, 172.25.230.1, 51743, None)
24/05/14 09:30:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(312, 172.25.230.1, 51743, None)
24/05/14 09:30:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(312, 172.25.230.1, 51743, None)
24/05/14 09:30:45 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/05/14 09:30:45 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@46580c8a for default.
24/05/14 09:30:45 INFO Executor: Fetching spark://dyn230-001.wireless-1725.ndsu.nodak.edu:63281/files/ShareGbest.py with timestamp 1715478123092
24/05/14 09:30:45 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.nodak.edu/172.25.230.1:63281 after 2 ms (0 ms spent in bootstraps)
24/05/14 09:30:45 INFO Utils: Fetching spark://dyn230-001.wireless-1725.ndsu.nodak.edu:63281/files/ShareGbest.py to /private/var/folders/rh/d6ltsplj4f94dtzy8y9sz6lr0000gn/T/spark-a650efa9-c97f-462c-aa15-8b9d5ca02f7f/executor-6a868077-836d-4f08-85f0-8e89105020a9/spark-6641ec93-f46c-46e6-b6ad-333aa302018c/fetchFileTemp1978837506998748173.tmp
24/05/14 09:30:45 INFO Utils: Copying /private/var/folders/rh/d6ltsplj4f94dtzy8y9sz6lr0000gn/T/spark-a650efa9-c97f-462c-aa15-8b9d5ca02f7f/executor-6a868077-836d-4f08-85f0-8e89105020a9/spark-6641ec93-f46c-46e6-b6ad-333aa302018c/18114131241715478123092_cache to /opt/homebrew/Cellar/apache-spark/3.5.0/libexec/work/app-20240511204204-0020/312/./ShareGbest.py
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 43
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 44
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 45
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 46
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 47
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 48
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 49
24/05/14 09:30:45 INFO CoarseGrainedExecutorBackend: Got assigned task 50
24/05/14 09:30:45 INFO Executor: Running task 0.2 in stage 6.0 (TID 46)
24/05/14 09:30:45 INFO Executor: Running task 2.2 in stage 6.0 (TID 50)
24/05/14 09:30:45 INFO Executor: Running task 3.2 in stage 6.0 (TID 45)
24/05/14 09:30:45 INFO Executor: Running task 7.2 in stage 6.0 (TID 44)
24/05/14 09:30:45 INFO Executor: Running task 4.2 in stage 6.0 (TID 47)
24/05/14 09:30:45 INFO Executor: Running task 1.2 in stage 6.0 (TID 48)
24/05/14 09:30:45 INFO Executor: Running task 5.2 in stage 6.0 (TID 43)
24/05/14 09:30:45 INFO Executor: Running task 6.2 in stage 6.0 (TID 49)
24/05/14 09:30:45 INFO TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
24/05/14 09:30:45 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.nodak.edu/172.25.230.1:63284 after 4 ms (0 ms spent in bootstraps)
24/05/14 09:30:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 366.3 MiB)
24/05/14 09:30:46 INFO TorrentBroadcast: Reading broadcast variable 9 took 135 ms
24/05/14 09:30:46 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.1 KiB, free 366.3 MiB)
Iteration 0, Core ID 97329: gbest_position: [26.679537767381902, 68.11252907014115]
Iteration 0, Core ID 97327: gbest_position: [34.15876676475038, 65.55571400485992]
Iteration 0, Core ID 97328: gbest_position: [36.76174627061111, 74.85485466554996]
Iteration 0, Core ID 97332: gbest_position: [28.399344766176736, 76.25586141041373]
Iteration 0, Core ID 97331: gbest_position: [34.37906793806275, 75.8848293379805]
Iteration 0, Core ID 97333: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 0, Core ID 97326: gbest_position: [27.62526222046146, 76.03493790416714]
Iteration 0, Core ID 97330: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 1, Core ID 97329: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 1, Core ID 97327: gbest_position: [19.97680778419035, 72.53089647716415]
Iteration 1, Core ID 97328: gbest_position: [30.47568717191463, 73.03935224175464]
Iteration 1, Core ID 97332: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 1, Core ID 97333: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 1, Core ID 97331: gbest_position: [29.429277414154896, 76.23521540899426]
Iteration 1, Core ID 97326: gbest_position: [27.46446618803386, 67.18834804698352]
Iteration 1, Core ID 97330: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 2, Core ID 97326: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 2, Core ID 97329: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 2, Core ID 97331: gbest_position: [32.282332842533826, 66.92485647842008]
Iteration 2, Core ID 97327: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 2, Core ID 97333: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 2, Core ID 97332: gbest_position: [25.685740778394102, 72.29015793648257]
Iteration 2, Core ID 97328: gbest_position: [31.695982137236825, 75.91355864829669]
Iteration 2, Core ID 97330: gbest_position: [26.720770349742672, 67.82187925285211]
24/05/14 09:34:01 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
Iteration 3, Core ID 97332: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97331: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97327: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97329: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97326: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97333: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 3, Core ID 97330: gbest_position: [25.8180700586664, 67.83679377756069]
Iteration 3, Core ID 97328: gbest_position: [26.720770349742672, 67.82187925285211]
24/05/14 09:34:41 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/05/14 09:35:26 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1219)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:48)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
Iteration 4, Core ID 97332: gbest_position: [30.974318029606273, 69.9009009624645]
Iteration 4, Core ID 97327: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 4, Core ID 97333: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 4, Core ID 97331: gbest_position: [32.051579723950596, 68.95332904447427]
Iteration 4, Core ID 97329: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 4, Core ID 97330: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 4, Core ID 97326: gbest_position: [26.720770349742672, 67.82187925285211]
Iteration 4, Core ID 97328: gbest_position: [39.99399610797852, 69.80524968025948]
24/05/14 09:35:36 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from dyn230-001.wireless-1725.ndsu.nodak.edu:63281 in 10000 milliseconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at scala.util.Failure.recover(Try.scala:234)
	at scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from dyn230-001.wireless-1725.ndsu.nodak.edu:63281 in 10000 milliseconds
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)
	... 7 more
