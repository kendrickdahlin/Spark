Spark Executor Command: "/Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java" "-cp" "/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/conf/:/opt/homebrew/Cellar/apache-spark/3.5.0/libexec/jars/*" "-Xmx1024M" "-Dspark.driver.port=49696" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:49696" "--executor-id" "204" "--hostname" "192.168.1.105" "--cores" "8" "--app-id" "app-20240509104538-0003" "--worker-url" "spark://Worker@192.168.1.105:63031" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/05/09 10:56:39 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 58181@dyn230-001.wireless-1725.ndsu.NoDak.edu
24/05/09 10:56:39 INFO SignalUtils: Registering signal handler for TERM
24/05/09 10:56:39 INFO SignalUtils: Registering signal handler for HUP
24/05/09 10:56:39 INFO SignalUtils: Registering signal handler for INT
24/05/09 10:56:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/05/09 10:56:43 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/09 10:56:43 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/09 10:56:43 INFO SecurityManager: Changing view acls groups to: 
24/05/09 10:56:43 INFO SecurityManager: Changing modify acls groups to: 
24/05/09 10:56:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/09 10:56:45 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.NoDak.edu/172.25.230.1:49696 after 457 ms (0 ms spent in bootstraps)
24/05/09 10:56:46 INFO SecurityManager: Changing view acls to: aaronmackenzie
24/05/09 10:56:46 INFO SecurityManager: Changing modify acls to: aaronmackenzie
24/05/09 10:56:46 INFO SecurityManager: Changing view acls groups to: 
24/05/09 10:56:46 INFO SecurityManager: Changing modify acls groups to: 
24/05/09 10:56:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: aaronmackenzie; groups with view permissions: EMPTY; users with modify permissions: aaronmackenzie; groups with modify permissions: EMPTY
24/05/09 10:56:46 INFO TransportClientFactory: Successfully created connection to dyn230-001.wireless-1725.ndsu.NoDak.edu/172.25.230.1:49696 after 21 ms (0 ms spent in bootstraps)
24/05/09 10:56:47 INFO DiskBlockManager: Created local directory at /private/var/folders/rh/d6ltsplj4f94dtzy8y9sz6lr0000gn/T/spark-b3602b3e-7e5d-407b-874b-20bf9b4a6e3a/executor-5c4a17aa-b29d-4abd-b70c-ffa53260d5da/blockmgr-99d4cd24-d3c4-4418-8a64-54043a3b23a5
24/05/09 10:56:47 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/05/09 10:56:49 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@dyn230-001.wireless-1725.ndsu.nodak.edu:49696
24/05/09 10:56:49 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.105:63031
24/05/09 10:56:49 INFO ResourceUtils: ==============================================================
24/05/09 10:56:49 INFO ResourceUtils: No custom resources configured for spark.executor.
24/05/09 10:56:49 INFO ResourceUtils: ==============================================================
24/05/09 10:56:50 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
24/05/09 10:56:50 INFO Executor: Starting executor ID 204 on host 192.168.1.105
24/05/09 10:56:50 INFO Executor: OS info Mac OS X, 14.4.1, x86_64
24/05/09 10:56:50 INFO Executor: Java version 1.8.0_401
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:51 WARN Utils: Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on a random free port. You may check whether configuring an appropriate binding address.
24/05/09 10:56:52 ERROR CoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Can't assign requested address: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
java.net.BindException: Can't assign requested address: Service 'org.apache.spark.network.netty.NettyBlockTransferService' failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service 'org.apache.spark.network.netty.NettyBlockTransferService' (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:438)
	at sun.nio.ch.Net.bind(Net.java:430)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:225)
	at io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:141)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:562)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1334)
	at io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:600)
	at io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:579)
	at io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:973)
	at io.netty.channel.AbstractChannel.bind(AbstractChannel.java:260)
	at io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:356)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
24/05/09 10:56:52 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
24/05/09 10:56:52 INFO MemoryStore: MemoryStore cleared
24/05/09 10:56:52 INFO BlockManager: BlockManager stopped
24/05/09 10:56:53 INFO ShutdownHookManager: Shutdown hook called
