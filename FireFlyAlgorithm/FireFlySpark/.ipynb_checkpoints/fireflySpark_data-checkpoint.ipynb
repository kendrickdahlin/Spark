{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7a4303",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fireflies_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    124\u001b[0m     fa \u001b[38;5;241m=\u001b[39m FireflyAlgorithm()\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4Cluster2D.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 102\u001b[0m, in \u001b[0;36mFireflyAlgorithm.run\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m points \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    100\u001b[0m points_rdd \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mparallelize(points)\n\u001b[0;32m--> 102\u001b[0m center \u001b[38;5;241m=\u001b[39m \u001b[43mfireflies_rdd\u001b[49m\u001b[38;5;241m.\u001b[39mmapPartitions(\u001b[38;5;28;01mlambda\u001b[39;00m fireflies: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_center(points_rdd)])\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#clean appearance\u001b[39;00m\n\u001b[1;32m    104\u001b[0m center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m point: \u001b[38;5;28mlist\u001b[39m(point), center))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fireflies_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "##SPLITS PARTICLES INTO PARTITIONS\n",
    "class FireflyAlgorithm:\n",
    "    def __init__(self, n_fireflies=56, max_iter=20, alpha=0.3, beta0=1, gamma=0.04):\n",
    "        self.n_fireflies = n_fireflies\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.beta0 = beta0\n",
    "        self.gamma = gamma\n",
    "        self.lb = 0 \n",
    "        self.ub = 100\n",
    "        self.centroids = {}\n",
    "        self.points = []\n",
    "\n",
    "    def objective_function(self, x):\n",
    "        return np.sum(np.linalg.norm(self.points-x, axis = 1))\n",
    "\n",
    "    def find_center(self, points):\n",
    "        #clean points data\n",
    "        self.points = [list(i) for i in list(points)]\n",
    "        print(f\"Data length {len(self.points)}\")\n",
    "        dim = len(self.points[0])\n",
    "        \n",
    "        #initialize fireflies\n",
    "        fireflies = np.random.uniform(self.lb, self.ub, (self.n_fireflies, dim))\n",
    "        fitness = np.apply_along_axis(self.objective_function, 1, fireflies)\n",
    "        \n",
    "        \n",
    "        #set arbitrary global best\n",
    "        best_firefly = fireflies[0]\n",
    "        best_fitness = fitness[0]\n",
    "        \n",
    "        for k in range(self.max_iter):\n",
    "            k_alpha = self.alpha * (1-k/self.max_iter) # decreases alpha over time\n",
    "           \n",
    "            for i in range(self.n_fireflies):\n",
    "                for j in range(self.n_fireflies):\n",
    "                    ##Here check broadcast variable\n",
    "                    if fitness[j] < fitness[i]:\n",
    "                        #move firefly\n",
    "                        r = np.linalg.norm(np.subtract(fireflies[i], fireflies[j])) #distance\n",
    "                        beta = self.beta0 * np.exp(-self.gamma * r**2) #attractiveness\n",
    "                        random_factor = k_alpha * (np.random.rand(dim) - 0.5) #randomness\n",
    "                        #moves firefly based on equation \n",
    "                        fireflies[i] += beta * (np.subtract(fireflies[j],fireflies[i])) + random_factor\n",
    "                        fireflies[i] = np.clip(fireflies[i], self.lb, self.ub) # keeps new loc within range\n",
    "\n",
    "                        #update fitness\n",
    "                        fitness[i] = self.objective_function(fireflies[i])\n",
    "                        #update new best\n",
    "                    \n",
    "                        if fitness[i] < best_fitness:\n",
    "                            #update global best\n",
    "                            best_firefly = fireflies[i]\n",
    "                            best_fitness = fitness[i]\n",
    "        return best_firefly\n",
    "    \n",
    "    #returns string of classification\n",
    "    def classify(self, row):\n",
    "        distances = {}\n",
    "        for key, points in self.centroids.items():\n",
    "            coord = np.array(row)\n",
    "            distances[key]= np.linalg.norm(points-coord)\n",
    "        cls = min(distances, key = distances.get)\n",
    "        return cls\n",
    "    \n",
    "\n",
    "    def run(self, file_name):\n",
    "        # Create a SparkSession\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Firefly Algorithm with Spark\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        sc = spark.sparkContext\n",
    "        num_cores = sc.defaultParallelism  #Determine the number of available cores\n",
    "        self.n_fireflies = max(self.n_fireflies, num_cores) \n",
    "        \n",
    "\n",
    "        # Read the dataset from CSV file into a  DataFrame\n",
    "       \n",
    "        df = df.sample(frac=1) # shuffle df\n",
    "        ratio = 0.8\n",
    " \n",
    "        total_rows = df.shape[0]\n",
    "        train_size = int(total_rows*ratio)\n",
    "        \n",
    "        # Split data into test and train\n",
    "        train_df = df[0:train_size]\n",
    "        test_df = df[train_size:]\n",
    "\n",
    "        #train\n",
    "        feature_columns = train_df.columns[:-1]\n",
    "        class_column = train_df.columns[-1]\n",
    "        classes = train_df[class_column].unique()\n",
    "        classes.sort()\n",
    "        \n",
    "        \n",
    "        for cls in classes:\n",
    "            points = train_df[train_df[class_column] == cls][feature_columns].values\n",
    "            points_rdd = sc.parallelize(points)\n",
    "            center = points_rdd.mapPartitions(lambda points: [self.find_center(points)]).collect()\n",
    "            #clean appearance\n",
    "            center = list(map(lambda point: list(point), center))\n",
    "            \n",
    "            self.centroids[cls] = [sum(x) / len(center) for x in zip(*center)]\n",
    "            print(f\"Centroid for class {cls}: {self.centroids[cls]}\")\n",
    "                \n",
    "    \n",
    "        #test\n",
    "        accuracy = 0\n",
    "        count = 0\n",
    "        for row in test.collect():\n",
    "            row = list(row)\n",
    "            cls = self.classify(row[:-1])\n",
    "            if cls == row[-1]:\n",
    "                accuracy +=1\n",
    "            count +=1\n",
    "        print(\"Accuracy: \", accuracy/count)\n",
    "        # Stop the SparkSession\n",
    "        spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fa = FireflyAlgorithm()\n",
    "    fa.run(\"4Cluster2D.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33c257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
